{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBhpG1wc6XZw",
        "outputId": "0d4b0d79-8d88-4e6e-f426-349bde01388a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting meaningless\n",
            "  Downloading meaningless-1.0.0-py3-none-any.whl (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from meaningless) (4.12.3)\n",
            "Collecting ruamel.yaml>=0.17.21 (from meaningless)\n",
            "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xmltodict>=0.13.0 (from meaningless)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.2->meaningless) (2.5)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.21->meaningless)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xmltodict, ruamel.yaml.clib, ruamel.yaml, meaningless\n",
            "Successfully installed meaningless-1.0.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 xmltodict-0.13.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.6.0\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from gspread) (2.31.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from gspread) (2.27.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.2.1->gspread) (2024.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->gspread) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->gspread) (0.6.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (4.1.3)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.9.1->oauth2client) (3.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install meaningless\n",
        "!pip install tiktoken\n",
        "!pip install bs4\n",
        "!pip install gspread\n",
        "!pip install oauth2client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading CSV & JSON data and scraping Wikipedia\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import json\n",
        "from meaningless import WebExtractor\n",
        "import tiktoken\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import re"
      ],
      "metadata": {
        "id": "At2BqWNx6nCC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv.field_size_limit(2147483647)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwzTB0sd7WgP",
        "outputId": "61420677-b83c-4109-b1c9-e3573c17d87f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract sentences from data\n",
        "def extract_sentences(data, extraction):\n",
        "    sentences = []\n",
        "    for item in data:\n",
        "        try:\n",
        "            sentences.append(item[extraction])\n",
        "        except KeyError:\n",
        "            print(f\"Key '{extraction}' not found in data item. Skipping this item.\")\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "sWJL1Use6qL_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a dataframe from sentences\n",
        "def create_dataframe(sentences, id_prefix):\n",
        "    df = pd.DataFrame({'text': sentences})\n",
        "    df['id'] = id_prefix + df.reset_index().index.astype(str)\n",
        "    df = df[['id', 'text']]\n",
        "    return df"
      ],
      "metadata": {
        "id": "tLAaeYz26tQs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count tokens in a text\n",
        "def count_tokens(text):\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    return len(encoding.encode(text))"
      ],
      "metadata": {
        "id": "daaRNNX-7MPq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get data from an input source\n",
        "def get_data(input_source):\n",
        "    try:\n",
        "        if input_source.endswith('.jsonl'):\n",
        "            response = requests.get(input_source)\n",
        "            response.raise_for_status()\n",
        "            data = [json.loads(line) for line in response.text.splitlines()]\n",
        "        elif input_source.endswith('.csv'):\n",
        "            response = requests.get(input_source)\n",
        "            response.raise_for_status()\n",
        "            data = [row for row in csv.DictReader(response.text.splitlines())]\n",
        "        else:\n",
        "            # Assuming the input source is a Google Sheets URL\n",
        "            scope = ['https://spreadsheets.google.com/feeds',\n",
        "                     'https://www.googleapis.com/auth/drive']\n",
        "            creds = ServiceAccountCredentials.from_json_keyfile_name('rapid-agent-418714-5dd18281c337.json', scope)\n",
        "            client = gspread.authorize(creds)\n",
        "            sheet = client.open(\"Data_Blend\").sheet1\n",
        "            data = sheet.get_all_records()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching data from {input_source}: {e}\")\n",
        "        return None\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "STnskCs47S2f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_files(variables):\n",
        "    dfs = []\n",
        "    for i in range(len(variables)):\n",
        "        input_source = variables['input_source'][i]\n",
        "        begin_extraction = variables['begin_extraction'][i]\n",
        "        id_prefix = variables['id_prefix'][i]\n",
        "        data = get_data(input_source)\n",
        "        if data:\n",
        "            sentences = extract_sentences(data, begin_extraction)\n",
        "            df = create_dataframe(sentences, id_prefix)\n",
        "            df['token_count'] = df['text'].apply(count_tokens)\n",
        "            dfs.append(df)\n",
        "    all_data_df = pd.concat(dfs, ignore_index=True)\n",
        "    return all_data_df"
      ],
      "metadata": {
        "id": "Q3cMp0Z7zRQM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to scrape Wikipedia pages\n",
        "def scrape_wikipedia_pages(wikipedia_sources):\n",
        "    data = []\n",
        "    for i, row in wikipedia_sources.iterrows():\n",
        "        page = requests.get(row['input_source'])\n",
        "        soup = BeautifulSoup(page.content, 'html.parser')\n",
        "        for i in range(len(soup.find_all('p'))):\n",
        "            text = soup.find_all('p')[i].get_text()\n",
        "            text = text.replace('<p>', '').replace('</p>', '')\n",
        "            text = text.replace('<a href=\"', '').replace('\">', '')\n",
        "            text = text.replace('</a>', '')\n",
        "            id = row['id_prefix'] + str(i)\n",
        "            data.append({'id': id, 'text': text})\n",
        "    df = pd.DataFrame(data)\n",
        "    df['token_count'] = df['text'].apply(count_tokens)\n",
        "    return df"
      ],
      "metadata": {
        "id": "17yPeHK87oez"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract passages from the Bible\n",
        "def extract_bible_passages(df, books_of_bible):\n",
        "    bible = WebExtractor(translation='nlt')\n",
        "    data = []\n",
        "    for index, row in df.iterrows():\n",
        "        if row['input_source'] not in books_of_bible:\n",
        "            continue\n",
        "        for chapter in range(int(row['begin_extraction']), int(row['end_before']) + 1):\n",
        "            verse = 1\n",
        "            while True:\n",
        "                try:\n",
        "                    passage = bible.get_passage(row['input_source'], chapter, verse)\n",
        "                    passage = re.sub(r'[\\u00B9\\u00B2\\u00B3\\u2070-\\u209F]', '', passage)\n",
        "                    passage = re.sub(r'[^\\w\\s,;:.?!]', '', passage)\n",
        "                    id = row['input_source'] + str(chapter).zfill(3) + str(verse).zfill(2)\n",
        "                    data.append({'id': id, 'text': passage})\n",
        "                    verse += 1\n",
        "                except Exception:\n",
        "                    break\n",
        "    df = pd.DataFrame(data)\n",
        "    df['token_count'] = df['text'].apply(count_tokens)\n",
        "    return df"
      ],
      "metadata": {
        "id": "rRCfd_PgXx8p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "if __name__ == '__main__':\n",
        "    scope = ['https://spreadsheets.google.com/feeds',\n",
        "             'https://www.googleapis.com/auth/drive']\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name('rapid-agent-418714-5dd18281c337.json', scope)\n",
        "    client = gspread.authorize(creds)\n",
        "    sheet = client.open(\"Data_Blend\").worksheet(\"datasets\")\n",
        "    variables = pd.DataFrame(sheet.get_all_records())\n",
        "\n",
        "    books_of_bible = ['Genesis', 'Exodus', 'Leviticus', 'Numbers', 'Deuteronomy', 'Joshua', 'Judges', 'Ruth', '1 Samuel', '2 Samuel', '1 Kings', '2 Kings', '1 Chronicles', '2 Chronicles', 'Ezra', 'Nehemiah', 'Esther', 'Job', 'Psalms', 'Proverbs', 'Ecclesiastes', 'Song of Solomon', 'Isaiah', 'Jeremiah', 'Lamentations', 'Ezekiel', 'Daniel', 'Hosea', 'Joel', 'Amos', 'Obadiah', 'Jonah', 'Micah', 'Nahum', 'Habakkuk', 'Zephaniah', 'Haggai', 'Zechariah', 'Malachi', 'Matthew', 'Mark', 'Luke', 'John', 'Acts', 'Romans', '1 Corinthians', '2 Corinthians', 'Galatians', 'Ephesians', 'Philippians', 'Colossians', '1 Thessalonians', '2 Thessalonians', '1 Timothy', '2 Timothy', 'Titus', 'Philemon', 'Hebrews', 'James', '1 Peter', '2 Peter', '1 John', '2 John', '3 John', 'Jude', 'Revelation']\n",
        "\n",
        "    all_data_df = process_all_files(variables)\n",
        "    wikipedia_sources = variables[variables['input_source'].str.startswith('https://en.wikipedia.org/wiki/')]\n",
        "    wikipedia_df = scrape_wikipedia_pages(wikipedia_sources)\n",
        "    bible_df = extract_bible_passages(variables, books_of_bible)\n",
        "\n",
        "    final_df = pd.concat([all_data_df, wikipedia_df, bible_df], ignore_index=True)\n",
        "    final_df.to_csv('all_data.csv', index=False)"
      ],
      "metadata": {
        "id": "B33U6b1C7sP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "690aec85-df4c-4d60-bf68-c0996ace22be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-885e2fe6de06>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mwikipedia_sources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://en.wikipedia.org/wiki/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mwikipedia_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_wikipedia_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwikipedia_sources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mbible_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_bible_passages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooks_of_bible\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwikipedia_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbible_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-423e348ee0df>\u001b[0m in \u001b[0;36mextract_bible_passages\u001b[0;34m(df, books_of_bible)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     \u001b[0mpassage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbible\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_passage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                     \u001b[0mpassage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[\\u00B9\\u00B2\\u00B3\\u2070-\\u209F]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mpassage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\w\\s,;:.?!]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/meaningless/bible_web_extractor.py\u001b[0m in \u001b[0;36mget_passage\u001b[0;34m(self, book, chapter, passage)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_passage_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_passages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/meaningless/bible_web_extractor.py\u001b[0m in \u001b[0;36mget_passage_range\u001b[0;34m(self, book, chapter_from, passage_from, chapter_to, passage_to)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Defer to a direct search invocation when sourcing passages from the same chapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapped_chapter_from\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcapped_chapter_to\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{book} {capped_chapter_from}:{capped_passage_from} - {capped_passage_to}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Get the partial section of the first chapter being requested, omitting some initial passages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/meaningless/bible_web_extractor.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, passage_name)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0msource_site_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'version'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpassage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'interface'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'print'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0msource_site\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://www.biblegateway.com/passage/?{source_site_params}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_site\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# Don't collect contents from an invalid verse, since they do not exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_soup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#print(\"START\", name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourcepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         tag = self.soup.handle_starttag(\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourceline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0msourcepos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourcepos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \"\"\"\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# print(\"Start tag %s: %s\" % (name, attrs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         if (self.parse_only and len(self.tagStack) <= 1\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mendData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0mcontainerClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainerClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainerClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_was_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobject_was_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmost_recent_element\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mobject_was_parsed\u001b[0;34m(self, o, parent, most_recent_element)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mfix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_sibling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_sibling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_most_recent_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, parent, previous_element, next_element, previous_sibling, next_sibling)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZZ2NBokPAFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XDzRmTdO_5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfD9B_T8O_uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read variables from Google Sheets\n",
        "\"\"\"scope = ['https://spreadsheets.google.com/feeds',\n",
        "         'https://www.googleapis.com/auth/drive']\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name('rapid-agent-418714-5dd18281c337.json', scope)\n",
        "client = gspread.authorize(creds)\n",
        "sheet = client.open(\"Data_Blend\").worksheet(\"datasets\")\n",
        "variables = pd.DataFrame(sheet.get_all_records())"
      ],
      "metadata": {
        "id": "09nP3qNQ7ZGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each row in the Google Sheets\n",
        "\"\"\"for i in range(len(variables)):\n",
        "    input_source = variables['input_source'][i]\n",
        "    output_file = variables['output_file'][i]\n",
        "    begin_extraction = variables['begin_extraction'][i]\n",
        "    id_prefix = variables['id_prefix'][i]\n",
        "    data = get_data(input_source)\n",
        "    if data:\n",
        "        sentences = extract_sentences(data, begin_extraction)\n",
        "        df = create_dataframe(sentences, id_prefix)\n",
        "        df['token_count'] = df['text'].apply(count_tokens)\n",
        "        df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "iZnYuh8P7egX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67fc3b2-9346-48cf-c0f8-867b10b51559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key 'p' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n",
            "Key '1' not found in data item. Skipping this item.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def process_file(input_source, output_file, extraction, id_prefix):\n",
        "    data = get_data(input_source)\n",
        "    sentences = extract_sentences(data, extraction)\n",
        "    df = create_dataframe(sentences, id_prefix)\n",
        "    df['token_count'] = df['text'].apply(count_tokens)\n",
        "    df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "FAZH7i4J7PqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}